{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbfIM-rtxz0q"
      },
      "source": [
        "%%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kN3h7UYxz0s",
        "outputId": "a1f43531-4b59-4f3b-e592-e6e71ed43bda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/keras-team/keras-nlp.git@google-io-2023 tensorflow-text==2.12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SIEWadhKxz0s"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Vasco\\miniconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import keras_nlp\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as tf_text\n",
        "from tensorflow import keras\n",
        "from tensorflow.lite.python import interpreter\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PkFrgp1xz0t"
      },
      "source": [
        "%%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gGrymhOxz0t",
        "outputId": "d7270ae9-86c9-4686-f1cb-607e9fc06828"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul), but are not present in its tracked objects:   <tf.Variable 'token_embedding/embeddings:0' shape=(50257, 768) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
          ]
        }
      ],
      "source": [
        "gpt2_tokenizer = keras_nlp.models.GPT2Tokenizer.from_preset(\"gpt2_base_en\")\n",
        "gpt2_preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
        "    \"gpt2_base_en\",\n",
        "    sequence_length=256,\n",
        "    add_end_token=True,\n",
        ")\n",
        "gpt2_lm = keras_nlp.models.GPT2CausalLM.from_preset(\"gpt2_base_en\", preprocessor=gpt2_preprocessor)\n",
        "\n",
        "tl_dr = tf.constant(' TL;DR ')\n",
        "max_tokens = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTgAfB31xz0t"
      },
      "source": [
        "%%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUCSbh8bxz0t"
      },
      "outputs": [],
      "source": [
        "output = gpt2_lm.generate(\"My trip to Yosemite was\", max_length=200)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output.numpy().decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch-Y8JWqxz0t"
      },
      "source": [
        "%%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK_AMcaPxz0u"
      },
      "outputs": [],
      "source": [
        "output = gpt2_lm.generate(\"That Italian restaurant is\", max_length=200)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output.numpy().decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHEYMrJmxz0u"
      },
      "source": [
        "%%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mSZmf18Fxz0u"
      },
      "outputs": [],
      "source": [
        "cnn_ds = tfds.load('cnn_dailymail', as_supervised=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrCnxSYTxz0u"
      },
      "source": [
        "%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "ywXIS8ESxz0u",
        "outputId": "e0707857-2fc0-4e00-9aca-dd6c4a9630ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "291\n",
            "b\"By. Associated Press. PUBLISHED:. 14:11 EST, 25 October 2013. |. UPDATED:. 15:36 EST, 25 October 2013. The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A. State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located. TL;DR Bishop John Folda, of North Dakota, is taking time off after being diagnosed. He contracted the infection through contaminated food in Italy. Church members in Fargo, Grand Forks and Jamestown could have been exposed.\"\n",
            "b\"By. Associated Press. PUBLISHED:. 14:11 EST, 25 October 2013. |. UPDATED:. 15:36 EST, 25 October 2013. The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A. State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located.\"\n",
            "b'Bishop John Folda, of North Dakota, is taking time off after being diagnosed.\\nHe contracted the infection through contaminated food in Italy.\\nChurch members in Fargo, Grand Forks and Jamestown could have been exposed.'\n"
          ]
        }
      ],
      "source": [
        "for article, highlights in cnn_ds['train']:\n",
        "  combination = article + tl_dr + tf.strings.regex_replace(highlights, \"\\n\", \" \")\n",
        "  tokens = gpt2_tokenizer.tokenize([str(combination.numpy())])\n",
        "  token_count = tokens.flat_values.shape[0]\n",
        "  if token_count < max_tokens:\n",
        "    print(token_count)\n",
        "    print(combination.numpy())\n",
        "    print(article.numpy())\n",
        "    print(highlights.numpy())\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwHmVEnzxz0u"
      },
      "source": [
        "%%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "vsN56VBqxz0v"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " [elapsed time: 0:00:00] |                                  | (ETA:  --:--:--) \r"
          ]
        }
      ],
      "source": [
        "import progressbar\n",
        "\n",
        "short_texts = []\n",
        "total = len(cnn_ds['train'])\n",
        "progressbar_update_freq = 1000\n",
        "count = 0\n",
        "used = 0\n",
        "\n",
        "widgets = [' [',\n",
        "         progressbar.Timer(format= 'elapsed time: %s'),\n",
        "         '] ',\n",
        "           progressbar.Bar('*'),' (',\n",
        "           progressbar.ETA(), ') ',\n",
        "          ]\n",
        "bar = progressbar.ProgressBar(\n",
        "    maxval=total // progressbar_update_freq + 2,\n",
        "    widgets=widgets).start()\n",
        "\n",
        "for article, highlights in cnn_ds['train']:\n",
        "  combination = article + tl_dr + tf.strings.regex_replace(highlights, \"\\n\", \" \")\n",
        "  tokens = gpt2_tokenizer.tokenize([str(combination.numpy())])\n",
        "  token_count = tokens.flat_values.shape[0]\n",
        "  if token_count < max_tokens:\n",
        "    short_texts.append(combination)\n",
        "    used += 1\n",
        "  count += 1\n",
        "  if count % progressbar_update_freq == 0:\n",
        "    bar.update(count / progressbar_update_freq)\n",
        "\n",
        "print(f'Processed {count} articles of which {used} were used (had a token count smaller than {max_tokens}).')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wwOqmjmxz0v"
      },
      "source": [
        "%%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KCamxdGtxz0v"
      },
      "outputs": [],
      "source": [
        "def save_texts(texts):\n",
        "    np.savez('data/selected_texts.npz', texts)\n",
        "\n",
        "def load_texts():\n",
        "    restored_texts = list()\n",
        "    with np.load('data/selected_texts.npz', allow_pickle=True) as data:\n",
        "      for file in data.files:\n",
        "        restored_texts.extend(data[file].tolist())\n",
        "    return restored_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp8y4IdXxz0v"
      },
      "source": [
        "Save the list of short combinations of articles and summaries (sort of a checkpoint)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "THo4PBOjxz0v",
        "outputId": "2aa210e7-8881-4b9e-fcf9-57046fb0ec94"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a9b94917d011>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshort_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'short_texts' is not defined"
          ]
        }
      ],
      "source": [
        "save_texts(short_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRHPu1FBxz0v"
      },
      "source": [
        "%%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNjexdH8xz0v",
        "outputId": "c6528af8-54d2-4868-bfe0-edc9c5c07d31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "--2023-10-11 12:16:30--  https://github.com/vveloso/ai-in-practice-talk/raw/main/gpt-2/data/selected_texts.npz\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/vveloso/ai-in-practice-talk/main/gpt-2/data/selected_texts.npz [following]\n",
            "--2023-10-11 12:16:30--  https://raw.githubusercontent.com/vveloso/ai-in-practice-talk/main/gpt-2/data/selected_texts.npz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5477897 (5.2M) [application/octet-stream]\n",
            "Saving to: ‘data/selected_texts.npz’\n",
            "\n",
            "data/selected_texts 100%[===================>]   5.22M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-10-11 12:16:30 (106 MB/s) - ‘data/selected_texts.npz’ saved [5477897/5477897]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir data\n",
        "!wget https://github.com/vveloso/ai-in-practice-talk/raw/main/gpt-2/data/selected_texts.npz -O data/selected_texts.npz\n",
        "\n",
        "short_texts = load_texts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSKtLCGHxz0w"
      },
      "source": [
        "%%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "koO2wZWnxz0w"
      },
      "outputs": [],
      "source": [
        "tf_train_ds = tf.data.Dataset.from_tensor_slices(short_texts)\n",
        "processed_ds = tf_train_ds.map(gpt2_preprocessor, tf.data.AUTOTUNE).batch(20).cache().prefetch(tf.data.AUTOTUNE)\n",
        "part_of_ds = processed_ds.take(200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_OZ74Ywxz0w"
      },
      "source": [
        "%%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A1SSJ8Fxz0w",
        "outputId": "58b6d4a7-8399-421d-bfc6-67191d279a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "200/200 [==============================] - 334s 1s/step - loss: 2.5030 - accuracy: 0.4506\n",
            "Epoch 2/2\n",
            "200/200 [==============================] - 248s 1s/step - loss: 2.3592 - accuracy: 0.4704\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c0ae04bfb20>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpt2_lm.include_preprocessing = False\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "lr = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "    5e-5,\n",
        "    decay_steps=part_of_ds.cardinality() * num_epochs,\n",
        "    end_learning_rate=0.0,\n",
        ")\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "gpt2_lm.compile(\n",
        "    optimizer=keras.optimizers.experimental.Adam(lr),\n",
        "    loss=loss,\n",
        "    weighted_metrics=[\"accuracy\"])\n",
        "\n",
        "gpt2_lm.fit(part_of_ds, epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qmyfeR-xz0w"
      },
      "source": [
        "%%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPtFizea7iyc",
        "outputId": "e22b532d-f5a8-42fb-9125-edba79e7481a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'All flights have been suspended in London\\'s Luton Airport following the breakout of a \"significant\" fire in the airport\\'s Terminal 2 parking lot, the airport said in a statement on Wednesday. The airport said it would be closed until at least 3 p.m. local time, with passengers advised not to travel to the airport. TL;DR The fire at Terminal 2 is \"significant\" airport said. The airport said it will be shut until at least 3 p.m. local time. The blaze occurred in a parking lot in a Terminal 2 parking lot.'>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpt2_lm.generate(\"All flights have been suspended in London's Luton Airport following the breakout of a \\\"significant\\\" fire in the airport's Terminal 2 parking lot, the airport said in a statement on Wednesday. The airport said it would be closed until at least 3 p.m. local time, with passengers advised not to travel to the airport. TL;DR \", max_length=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_d8j3nVIEuX",
        "outputId": "6fd1184c-2093-40f8-e1c3-bfdbf13b3933"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b\"The House GOP's two candidates for speaker detailed their plans during a closed-door meeting on Tuesday for avoiding a government shutdown - a key issue for members, and one that sank Kevin McCarthy's speakership. House Majority Leader Steve Scalise and Judiciary Chairman Jim Jordan made their pitches during the Tuesday meeting ahead of a conference vote for speaker on Wednesday, but GOP lawmakers made clear that the conference remains divided, and there's a heavy dose of skepticism among Republicans that they will quickly coalesce around either candidate to be the next speaker. TL;DR  Speaker Paul Ryan's two contenders for speaker outline their plan. The two candidates are expected to address a closed-door conference vote for Speaker Paul Ryan. The House GOP's two candidates for speaker detailed their plans during closed-door meetings Tuesday.\">"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpt2_lm.generate(\"The House GOP's two candidates for speaker detailed their plans during a closed-door meeting on Tuesday for avoiding a government shutdown - a key issue for members, and one that sank Kevin McCarthy's speakership. House Majority Leader Steve Scalise and Judiciary Chairman Jim Jordan made their pitches during the Tuesday meeting ahead of a conference vote for speaker on Wednesday, but GOP lawmakers made clear that the conference remains divided, and there's a heavy dose of skepticism among Republicans that they will quickly coalesce around either candidate to be the next speaker. TL;DR \", max_length=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WGytoHuEhwmo"
      },
      "outputs": [],
      "source": [
        "gpt2_lm.backbone.save_weights(\"finetuned_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7UX4YinvzmYR"
      },
      "outputs": [],
      "source": [
        "gpt2_lm.backbone.load_weights(\"finetuned_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1LnhcchrUbsu"
      },
      "outputs": [],
      "source": [
        "del gpt2_tokenizer, gpt2_preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "aNobqZ9UBJJK"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def generate(prompt, max_length):\n",
        "    return gpt2_lm.generate(prompt, max_length)\n",
        "\n",
        "concrete_func = generate.get_concrete_function(tf.TensorSpec([], tf.string), 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "914-vg7ZBOCc"
      },
      "outputs": [],
      "source": [
        "def run_inference(input, generate_tflite):\n",
        "  interp = interpreter.InterpreterWithCustomOps(\n",
        "      model_content=generate_tflite,\n",
        "      custom_op_registerers=tf_text.tflite_registrar.SELECT_TFTEXT_OPS)\n",
        "  interp.get_signature_list()\n",
        "\n",
        "  generator = interp.get_signature_runner('serving_default')\n",
        "  output = generator(prompt=np.array([input]))\n",
        "  print(\"\\nGenerated with TFLite:\\n\", output[\"output_0\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnGHtItBBKEP",
        "outputId": "7596ce1f-15c0-48c5-b6d6-18242dacf4c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras_nlp.models.gpt2.gpt2_causal_lm_preprocessor.GPT2CausalLMPreprocessor object at 0x78abcbd7a680>, because it is not built.\n",
            "WARNING:absl:Found untraced functions such as gpt2_tokenizer_1_layer_call_fn, gpt2_tokenizer_1_layer_call_and_return_conditional_losses, cached_multi_head_attention_layer_call_fn, cached_multi_head_attention_layer_call_and_return_conditional_losses, layer_normalization_layer_call_fn while saving (showing 5 of 314). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generated with TFLite:\n",
            " b\"I'm enjoying a great weekend in London with friends and family. I've been looking forward to getting back to my hometown for the first time since the end of the World Cup. The weather is nice, there are no issues, and I'm feeling pretty safe and comfortable. I'll be staying at a lovely hotel with my wife and two young boys, who are both from Manchester City and Chelsea. The weather is good and the sun is setting, so I'm feeling really good! \\xc2\\xa0It\"\n"
          ]
        }
      ],
      "source": [
        "gpt2_lm.jit_compile = False\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func],\n",
        "                                                            gpt2_lm)\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "]\n",
        "converter.allow_custom_ops = True\n",
        "converter.target_spec.experimental_select_user_tf_ops = [\"UnsortedSegmentJoin\", \"UpperBound\"]\n",
        "converter._experimental_guarantee_all_funcs_one_use = True\n",
        "generate_tflite = converter.convert()\n",
        "run_inference(\"I'm enjoying a\", generate_tflite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "waKoU0YxH3SE"
      },
      "outputs": [],
      "source": [
        "with open('unquantized_gpt2.tflite', 'wb') as f:\n",
        "  f.write(generate_tflite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYpB2FyA_l3D",
        "outputId": "4f14ba76-5250-4029-8459-1532e9a0b641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 478M Oct 11 13:18 unquantized_gpt2.tflite\n"
          ]
        }
      ],
      "source": [
        "!ls -lh *.tflite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLFzGKIXbPeF",
        "outputId": "bd2777ed-f44c-46c0-b8ba-01bd6ab6310a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras_nlp.models.gpt2.gpt2_causal_lm_preprocessor.GPT2CausalLMPreprocessor object at 0x78abcbd7a680>, because it is not built.\n",
            "WARNING:absl:Found untraced functions such as gpt2_tokenizer_1_layer_call_fn, gpt2_tokenizer_1_layer_call_and_return_conditional_losses, cached_multi_head_attention_layer_call_fn, cached_multi_head_attention_layer_call_and_return_conditional_losses, layer_normalization_layer_call_fn while saving (showing 5 of 314). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generated with TFLite:\n",
            " b\"I'm enjoying a lot of things: reading my weekly weekly weekly newsletter, and then following up with some of your favorite\\xc2\\xa0quotes. See my written daily Journalist column, which features weekly written written written written for the Mail Mail.  \\xc2\\xa0You can\\xc2\\xa0quiz my weekly weekly written columns:\\xc2\\xa0quiz:\\xc2\\xa0quiz:\\xc2\\xa0Quiz:\\xc2\\xa0quiz:\\xc2\\xa0quiz:\\xc2\\xa0quiz:\\xc2\\xa0quiz:\\xc2\\xa0quiz:\\n\\xc2\\xa0quiz:\\xc2\\xa0\"\n"
          ]
        }
      ],
      "source": [
        "gpt2_lm.jit_compile = False\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func],\n",
        "                                                            gpt2_lm)\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "]\n",
        "converter.allow_custom_ops = True\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.experimental_select_user_tf_ops = [\"UnsortedSegmentJoin\", \"UpperBound\"]\n",
        "converter._experimental_guarantee_all_funcs_one_use = True\n",
        "quant_generate_tflite = converter.convert()\n",
        "run_inference(\"I'm enjoying a\", quant_generate_tflite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpbNScdIx7Rx",
        "outputId": "f2595578-4504-4aa0-f7fc-52ae72965965"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generated with TFLite:\n",
            " b'All flights have been suspended in London\\'s Luton Airport following the breakout of a \"significant\" fire in the airport\\'s Terminal 2 parking lot, the airport said in a statement on Wednesday. The airport said it would be closed until at least 3 p.m. local time, with passengers advised not to travel to the airport. TL;DR  Underground fire sparks at Terminal 2 parking lot. The blaze started around 6 p.m., the airport said. The blaze occurred at Terminal 2 parking lot'\n"
          ]
        }
      ],
      "source": [
        "run_inference(\"All flights have been suspended in London's Luton Airport following the breakout of a \\\"significant\\\" fire in the airport's Terminal 2 parking lot, the airport said in a statement on Wednesday. The airport said it would be closed until at least 3 p.m. local time, with passengers advised not to travel to the airport. TL;DR \", quant_generate_tflite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VfnpXjmyO_i",
        "outputId": "9769f7e1-70c0-4e54-fe60-95283f31dbe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generated with TFLite:\n",
            " b'All flights have been suspended in London\\'s Luton Airport following the breakout of a \"significant\" fire in the airport\\'s Terminal 2 parking lot, the airport said in a statement on Wednesday. The airport said it would be closed until at least 3 p.m. local time, with passengers advised not to travel to the airport. TL;DR  Airport shut down in London after a fire in terminal 2 parking lot. A \"significant\" fire broke out in Terminal 2 parking lot at Luton Airport'\n"
          ]
        }
      ],
      "source": [
        "run_inference(\"All flights have been suspended in London's Luton Airport following the breakout of a \\\"significant\\\" fire in the airport's Terminal 2 parking lot, the airport said in a statement on Wednesday. The airport said it would be closed until at least 3 p.m. local time, with passengers advised not to travel to the airport. TL;DR \", generate_tflite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "IwWuHksnkeIB"
      },
      "outputs": [],
      "source": [
        "with open('quantized_gpt2.tflite', 'wb') as f:\n",
        "  f.write(quant_generate_tflite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAsRgEonkxoG",
        "outputId": "c7e97a30-0b23-4375-c85b-fee82bcce065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 124M Oct 11 13:24 quantized_gpt2.tflite\n",
            "-rw-r--r-- 1 root root 478M Oct 11 13:18 unquantized_gpt2.tflite\n"
          ]
        }
      ],
      "source": [
        "!ls -lh *.tflite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "WD5aj3e-tHAh"
      },
      "outputs": [],
      "source": [
        "!mv quantized_gpt2.tflite summarise.tflite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "o9LsFkBa3r07"
      },
      "outputs": [],
      "source": [
        "del quant_generate_tflite, generate_tflite"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
